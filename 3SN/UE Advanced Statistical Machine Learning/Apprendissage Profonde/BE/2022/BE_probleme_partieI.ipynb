{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1ciEeyNevrd"
      },
      "source": [
        "#Problème:\n",
        "\n",
        "#Deux cas d'utilisation des données d'opportunité"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAkaS7_je3Is"
      },
      "source": [
        "La qualité de la description d'un phénomène physique dépend des moyens d'observation disponibles. Généralement, les moyens à disposition dépendent de la zone géographique et de la période considérée.\n",
        "Lorsque les capteurs sont peu nombreux, on peut chercher à compléter l'observation par des données supplémentaires issues de capteurs non spécifiques. On parle alors de *données d'opportunité*.\n",
        "\n",
        "Les *données d'opportunité* peuvent être exploitées par apprentissage. Une approche courante consiste à entraîner un modèle sur la zone où des capteurs spécifiques peuvent fournir une cible de qualité. Le modèle est ensuite porté là où seules les *données d'opportunité* sont disponibles.\n",
        "\n",
        "Aujourd'hui, on utilise par exemple des données issues des réseaux de télécommunication pour préciser la localisation et l'intensité de phénomènes physiques ou sociaux.  \n",
        "La première partie du problème est inspirée du cas où la donnée opportune est une atténuation du signal échangé entre les antennes d'un réseau mobile.\n",
        "\n",
        "On cherche aussi à exploiter des données issues de capteurs de mauvaise qualité qui peuvent être beaucoup plus nombreux que les capteurs spécifiques. C'est ce qu'illustre la seconde partie.\n",
        "\n",
        "**Note**: les deux parties du problème sont complètement indépendantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSgiKnAs1BbN"
      },
      "source": [
        "**Partie I - problème n°1 : régression avec un UNet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mU0zdFYCLdgR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFkJEv24N5Rn",
        "outputId": "47c49b22-05aa-480c-f309-7844d3b97773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-10 19:01:50--  https://www.grosfichiers.com/HAnmgiuVNGn_XtdcYCeMNnJ\n",
            "Resolving www.grosfichiers.com (www.grosfichiers.com)... 51.68.254.173\n",
            "Connecting to www.grosfichiers.com (www.grosfichiers.com)|51.68.254.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27402 (27K) [application/octet-stream]\n",
            "Saving to: ‘HAnmgiuVNGn_XtdcYCeMNnJ’\n",
            "\n",
            "HAnmgiuVNGn_XtdcYCe 100%[===================>]  26.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-10 19:01:51 (232 MB/s) - ‘HAnmgiuVNGn_XtdcYCeMNnJ’ saved [27402/27402]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Lien valable jusqu'au 17/01/2024:\n",
        "# module à charger\n",
        "! wget https://www.grosfichiers.com/HAnmgiuVNGn_XtdcYCeMNnJ\n",
        "! mv HAnmgiuVNGn_XtdcYCeMNnJ utile_BE.py\n",
        "! mkdir data\n",
        "from utile_BE import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlQHRrfQqmKw"
      },
      "source": [
        "Dans ce problème, la cible $T$ est un champ physique scalaire, positif ou nul. On suppose que, dans le meilleur des cas, deux types de capteurs spécifiques sont disponibles.\\\n",
        "Le premier type fournit une mesure spatialisée du champ. Il n'est pas partout disponible. Le second type de capteur fournit une mesure ponctuelle. Ces capteurs sont implantés sur toute la zone d'intérêt mais il ne couvrent correctement que 0.5% de la surface.\\\n",
        "En plus de ces capteurs, on suppose qu'on a accès à des données issues d'un réseau de télécommunications. Ces données réflètent l'atténuation d'un signal échangé entre des antennes relais. On suppose que pour chaque signal émis entre deux antennes $A_i$, $A_j$, on peut calculer une quantité $S(A_i,A_j;T)$ qui ne dépend que de la valeur moyenne du champ $T$ sur le trajet entre $A_i$ et $A_j$.\n",
        "\n",
        "On se place dans le cas où un jeu est constitué sur la zone où la mesure spatialisée du champ est disponible. Pour une première preuve de concept, on travaille avec des images de synthèse sur lesquelles:\n",
        "- les mesures ponctuelles ont été attribuées aux pixels qui leur correspondent.\n",
        "- les données d'opportunité sont représentées par des segments. Les extrémités d'un segment représentent deux antennes $A_i$, $A_j$. Le long d'un segment, l'intensité des pixels est constante, de valeur $S(A_i,A_j;T)$ (seule exception, dans le cas d'intersections, les valeurs sont simplement sommées - voir ci-dessous)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd1BiavmQnmO"
      },
      "outputs": [],
      "source": [
        "batch_size = 6\n",
        "p = 0.5 / 100\n",
        "full_target, partial_target, integrated_signals  = gen_image_with_integrated_signals(batch_size, p)\n",
        "\n",
        "\n",
        "fig1 = plt.figure(1, figsize=(36, 6))\n",
        "# champ T\n",
        "voir_batch2D(full_target, 6, fig1, k=0, min_scale=0, max_scale=1)\n",
        "\n",
        "# mesures ponctuelles\n",
        "fig2 = plt.figure(2, figsize=(36, 6))\n",
        "voir_batch2D(partial_target, 6, fig2, k=0, min_scale=-1, max_scale=1)\n",
        "\n",
        "# représentation des données d'opportunité par des segments\n",
        "fig3 = plt.figure(3, figsize=(36, 6))\n",
        "voir_batch2D(integrated_signals, 6, fig3, k=0, min_scale=0, max_scale=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBqBbKylu3qf"
      },
      "source": [
        "Dans la cellule précédente, la fonction *gen_image_with_integrated_signals* permet de visualiser le jeu simulé:\n",
        "- *full_target* représente le champ $T$ vu par le premier type de capteur spécifique sur la zone couverte par l'image. Il s'agit de disques de valeurs positives.\n",
        "- *partial_target* représente les mesures ponctuelles. En dehors des points de mesure, la valeur est fixée à -1.\n",
        "- *integrated_signals* contient la représentation par segments. En dehors des segments, la valeur est fixée à 0. Dans cette simulation simpliste, les segments ont tous été supposés parallèles à l'un des deux côtés de l'image. De plus, $S$ a été modélisé comme une fonction affine, croissante de la valeur moyenne sur le segment. Ainsi, l'intensité d'un segment croit avec le nombre de disques traversés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjk_hImGoknf"
      },
      "source": [
        "Dans cette partie, le but est de dire:\\\n",
        "**A.** si l'on peut entraîner avec succès un *FCN* à restituer $T$ **à partir** de données d'opportunité représentées par des segments (**exercice 1**).\\\n",
        "**B.** si en combinant des données d'opportunité aux mesures ponctuelles, on améliore bien les performances d'un $FCN$ (**exercice 2**)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4qSC2Sp0Vu1"
      },
      "source": [
        "**Exercice 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mbQk5JJxhri"
      },
      "source": [
        "**Q1** Dans la cellule suivante, instancier un UNet. Choisir correctement *ch_in* et *ch_out*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lKrkjdHRSBG"
      },
      "outputs": [],
      "source": [
        "ch_in = 1  # Assuming grayscale images\n",
        "ch_out = 1 # Predicting a scalar field T\n",
        "size = 8   # Assuming this is a predefined parameter for the model\n",
        "\n",
        "fcn = UNet(ch_in, ch_out, size).cuda()  # Instantiate the UNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKeHuXmt0j22"
      },
      "source": [
        "**Q2** Combien de poids ce réseau contient-il ? Ecrire le calcul ou intégrer un bout de code qui conduit au résultat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9zJd62r0n79"
      },
      "outputs": [],
      "source": [
        "total_params = sum(p.numel() for p in fcn.parameters() if p.requires_grad)\n",
        "print(f\"Total number of trainable parameters in the network: {total_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Heo9DMy0wvN"
      },
      "source": [
        "**Q3** Présenter brièvement les types de couches utilisées dans ce réseau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMlLGY8f1D2F"
      },
      "source": [
        "A typical UNet architecture contains the following types of layers:\n",
        "- Convolutional layers (Conv2d): For feature extraction and learning spatial hierarchies.\n",
        "- Activation layers (like ReLU): For introducing non-linearity to the model.\n",
        "- Pooling layers (MaxPool2d): To reduce spatial dimensions and increase field of view.\n",
        "- Upsampling layers: To increase spatial dimensions in the expansive path.\n",
        "- Skip connections: To concatenate features from the contracting path with the upsampled output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4TOsQlI1EgU"
      },
      "source": [
        "**Q4** Dans la cellule suivante, coder en une ligne l'erreur absolue moyenne (MAE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpAnjlZD0hrk"
      },
      "outputs": [],
      "source": [
        "def criterion(output, target):\n",
        "    return torch.mean(torch.abs(output - target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2-jqJbQ1SqB"
      },
      "source": [
        "**Q5** Instancier l'optimizer Adam avec un taux d'apprentissage de 0.0002."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vn9-oNyRUgu"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(fcn.parameters(), lr=0.0002)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE69GIUQ5Yl7"
      },
      "source": [
        "**Q6** Pourquoi est-il, en général, nécessaire de passer par une étape de validation lors d'un apprentissage ? Pourquoi peut-on s'en passer dans le cas où les images sont générées la volée ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boDjmqHV5tBz"
      },
      "source": [
        "In machine learning, a validation step is essential for several reasons:\n",
        "\n",
        "- Model Evaluation: It helps assess the model's performance on unseen data, ensuring that the model generalizes well beyond the training dataset.\n",
        "- Hyperparameter Tuning: It aids in fine-tuning model parameters to avoid overfitting.\n",
        "- Model Selection: It allows comparison between different models or configurations.\n",
        "\n",
        "However, when images are generated on the fly (like in data augmentation or with synthetic data), the model is continuously exposed to new variations of data. This setup reduces the risk of overfitting as the model doesn't see the exact same images repeatedly. In such cases, a separate validation set might be less critical, though it's still often used to monitor for overfitting and for model selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uzKkqfa4fQo"
      },
      "source": [
        "**Q7** Ecrire la boucle d'apprentissage. On stockera la MAE à chaque époque.\n",
        "- nombre d'époque : 30\n",
        "- batches par époque : 100\n",
        "- taille de batch : 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGsbUI9iRXQt"
      },
      "outputs": [],
      "source": [
        "nepochs = 30\n",
        "nbatches = 100\n",
        "batchsize = 32\n",
        "\n",
        "train_losses = []\n",
        "\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "\n",
        "\n",
        "    print(\"Epoch \" + str(epoch))\n",
        "    epoch_losses  = []\n",
        "    for i in range(nbatches):    # nbatch = datasetsize/batchsize\n",
        "        #Load inputs\n",
        "        inputs, targets = gen_image_with_integrated_signals(batchsize, p)\n",
        "        outputs = fcn(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_losses.append(loss.detach().cpu())\n",
        "\n",
        "        del target, input, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    epoch_loss = np.mean(epoch_losses)\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "    print('epoch loss : \\n')\n",
        "    print(epoch_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuJSiE9r6fkq"
      },
      "source": [
        "**Q8** Visualisez les résultats. Quelle conséquence visible le choix de la fonction de coût a-t-il eu ? Conclure sur le point **A.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(train_losses)\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error (MAE)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jb1aqsgHzoQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of Mean Absolute Error (MAE) as a loss function is significant because it measures the average magnitude of errors in the predictions. It treats all errors equally, unlike Mean Squared Error which penalizes larger errors more severely. This can make the model more robust to outliers but could lead to underfitting if there are systematic larger errors in the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "ffERO42ZzsL8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJR_FpQ48RL_"
      },
      "source": [
        "**Exercice 2**\n",
        "\n",
        "On souhaite montrer qu'un *fcn* peut utiliser simultanément les deux types de signaux (mesures ponctuelles et données d'opportunité).\n",
        "Reprendre le code de **l'exercice 1** avec les deux champs en entrée. Comparer les performances aux plans quantitatif (courbes d'apprentissage) et qualitatif. Conclure."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusting the number of input channels\n",
        "ch_in = 2  # Assuming both point measurements and opportunity data are single-channel\n",
        "fcn = UNet(ch_in, ch_out, size).cuda()\n",
        "\n",
        "# Modified training loop\n",
        "train_losses_ex2 = []\n",
        "\n",
        "for epoch in range(nepochs):\n",
        "    print(f\"Epoch {epoch + 1}/{nepochs}\")\n",
        "    epoch_losses = []\n",
        "\n",
        "    for _ in range(nbatches):\n",
        "        full_target, partial_target, integrated_signals = gen_image_with_integrated_signals(batchsize, p)\n",
        "\n",
        "        # Combine partial_target and integrated_signals for input\n",
        "        combined_input = torch.stack([partial_target, integrated_signals], dim=1)\n",
        "\n",
        "        outputs = fcn(combined_input)\n",
        "        loss = criterion(outputs, full_target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_losses.append(loss.item())\n",
        "\n",
        "    epoch_loss = np.mean(epoch_losses)\n",
        "    train_losses_ex2.append(epoch_loss)\n",
        "    print(f'Epoch Loss: {epoch_loss}')\n",
        "\n",
        "# Plotting the learning curve for Exercise 2\n",
        "plt.plot(train_losses_ex2, label='Exercise 2')\n",
        "plt.title('Training Loss Over Epochs (Exercise 2)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Absolute Error (MAE)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Discussion and conclusion based on the comparison of learning curves and qualitative assessment\n"
      ],
      "metadata": {
        "id": "hZNq5KqB0Ah9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}